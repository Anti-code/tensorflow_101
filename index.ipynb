{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notebook'u yayınladığım site bu işi bilim adına gönüllü olarak yapıyor. \n",
    "\n",
    "# Henüz hesap ve dosya erişim sistemini oluşturmadılar.\n",
    "\n",
    "# Diğerlerininde faydalanmasını sağlamak için lütfen notebook'u \n",
    "\n",
    "# Sadece Çalıştırın Değiştirmeyin\n",
    "\n",
    "# Düzenlemek İçin File -> Make a Copy yolunu kullanarak notebook'u klonlayabilirsiniz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Tensorflow C++ da yazıdı bu yüzden pythondaki verileri doğrudan kütüphanede kullanamıyoruz.\n",
    "    Verileri kullanabilmek için tensorflowun bize sunduğu veri yapılarını kullanmamız gerekiyor.\n",
    "\n",
    "    - Variable() değişkenleri\n",
    "    - constant() sabit değerleri\n",
    "    - placeholder() geçici olarak değer tutan veri yapılarını temsil ediyor\n",
    "\n",
    "    Bu veri yapılarında çeşitli boyutlardaki matrisleri tutabiliriz. \n",
    "    Veri türü olarak python listelerini, numpy dizilerini veya tensorflow dizilerini kullanabiliriz.\n",
    "    Ayrıca istersek tanımladığımız veri yapılarını adlandırabiliriz. Tensorflow öntanımlı olarak 32 bit float\n",
    "    veriler ile işlemler yapıyor.\n",
    "\n",
    "    Kullanımı:\n",
    "        v = tf.Variable(matris, name=\"isim\")\n",
    "        p = tf.placeholder(matris, name=\"isim\")\n",
    "        c = tf.constant(matris, name=\"isim\")\n",
    "\n",
    "\n",
    "\n",
    "    Yapay Sinir Hucresi:\n",
    "$$Sinyal = AktivasyonFonksiyonu({AgirlikMatrisi * Girdi + SapmaDegeri})$$\n",
    "\n",
    "    Agirlik matrisleri (weights) yapay sinir aglarindaki hafizayi temsil ediyor.\n",
    "    Yapay Sinir Aginda bu matrisleri, gelen veriler ve sonrasinda kullandigimiz optimizasyon algoritmasi\n",
    "    ile sekillendiriyoruz. Yapay sinir agi boyle ogreniyor.\n",
    "\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Agirlik matrisini sadece girdilerle sekillendirerek aktivasyon fonksiyonunu esnek bir sekilde kullanmayiz. \n",
    "      Aktivasyon fonksiyonlarından biri olan sigmoid fonksiyonunun biassız ve bias eklenmiş grafiklerini\n",
    "      inceleyelim.\n",
    "$$ sigmoid: y = 1/(1+e^{-x}) $$\n",
    "\n",
    "![](neuron_1.gif)![](sigmoid_1.png) ![](neuron_2.gif) ![](sigmoid_2.png)\n",
    "    \n",
    "    Aktivasyon fonksiyonu yapay sinir hucresinin urettigi sinyalin gucune gore hucrenin aktif olup olmayacagini\n",
    "    veya ne olcude aktif olacagini belirler.\n",
    "    sigmoid, tanh, step bu fonksiyonlara örnek verilebilir \n",
    "\n",
    "    Yapay zekanın ogrenmesini saglamak icin tahmin edilen veriler ile dogru verileri kıyaslayıp,\n",
    "    aralarındaki kaybi(hatayi) hesaplayip azaltmamiz gerekiyor\n",
    "    \n",
    "    Bu hatayi hesaplamak icin;\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y_real))    \n",
    "\n",
    "    islemini kullanıyoruz. Burada oncelikle iki deger arasindaki farkı hesapladık. \n",
    "    Ardindan belirginlestirmek icin farkin karesini aldik. Son olarak da reduce_mean() \n",
    "    fonksiyonu ile kaybin ortalama degerini olctuk. Bu fonksiyon parametre olarak \n",
    "    input_tensor (giris matrisini) aliyor. Ek olarak hangi boyuta gore ortalama alinacagi\n",
    "    belirlenebiliyor.\n",
    "\n",
    "    Bu hatayi optimizasyon algoritmalari ile azaltabiliriz. Tensorflow bize hazir kullanabilecegimiz \n",
    "    bazi optimizasyon algoritmalari sunuyor. Biz bunlar arasindan GradientDescentOptimizer'i kullanacagiz.\n",
    "![](gdo.png)\n",
    "\n",
    "    Bu algoritma N boyutlu hata matrisinde minumum noktayi bulmayi hedefliyor.\n",
    "    Bu algoritmayi;\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "    seklinde kullanabiliriz. Girdigimiz 0.5 degeri ogrenme oranini temsil ediyor. \n",
    "    Bu degeri cok yuksek yaparsak minumum noktayi es gecebiliriz, cok kucuk yaparsak da\n",
    "    minimum noktaya ulasmamiz cok uzun surebilir. \n",
    "    \n",
    "    Tensorflow \"lazy\" calisiyor yani tanimladigimiz degiskenler, fonsiyonlar, optimizasyon algoritmalari \n",
    "    tanimladigimiz anda calistirilmiyor. Bu islemleri aktif etmek icin tensorflow oturumu (Session) kullanmamiz\n",
    "    gerekiyor. Session'u bir isaretci olarak dusunulebilir. Tanimladigimiz yapay sinir agi modelinin istedigimiz\n",
    "    adimini Session ile calistirip degerini alabiliriz.\n",
    "\n",
    "    Asagida en basit haliyle bir yapay sinir agi olusturduk. Giris verileri icin (X) -1 ile 1 arasinda rastgele sayilardan olusan 3x3 bir matris olusturduk.\n",
    "    Gercek verileri temsil etmek icinde giris verilerinde biraz oynama yaptik. Bu ornekteki amacimiz giris matrisini(X) ile yapay sinir agini egiterek her adimda\n",
    "    gercek degerlere(y_real) biraz daha yaklasmak. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30501819  0.37679443  0.39487767]\n",
      " [ 0.32714039  0.36743698  0.32770458]\n",
      " [ 0.38853815  0.38401783  0.38375115]]\n"
     ]
    }
   ],
   "source": [
    "# Rastgele veriler oluşturduk\n",
    "X = np.random.rand(3, 3).astype(np.float32)\n",
    "y_real = X * 0.1 + 0.3\n",
    "print(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) # 1D array,  [-0.322323, 0.612312, ... , 0.712342]\n",
    "biases = tf.Variable(tf.zeros([1])) # [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = weights * X + biases # giris verilerine gore bir tahmin olustur (sinir hucresi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_pred - y_real)) # kaybi hesapla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.5) # learning_rate < 1\n",
    "train = optimizer.minimize(loss) # modeli optimize et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Eğer Variable() tanımlamışsak tensorflowun  bu değişkenleri tanıması için \n",
    "    tf.global_variables_initializer() fonksiyonunu çalıştırmamız gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # important, degiskenleri tanimla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Eğitimin her aşamasında modelin tahmit ettiği değerlerin asıl değerlere yaklaşmasını umuyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.02979365] [ 0.60090828]\n",
      "200 [ 0.09999987] [ 0.3000001]\n",
      "400 [ 0.09999988] [ 0.3000001]\n",
      "600 [ 0.09999988] [ 0.3000001]\n",
      "800 [ 0.09999988] [ 0.3000001]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "sess = tf.Session() # pointer\n",
    "sess.run(init) # degiskenler tanimlandi\n",
    "for step in range(1000):\n",
    "    sess.run(train) # Modeli 1 kez egittik. train -> optimizer -> loss -> (y_pred, y_real) -> Wx_plus_B -> W, X, B\n",
    "\n",
    "    if step % 200 is 0: # 200 adimda bir\n",
    "        # agirlik matrisini ve sapma degerini yazdirdik. (Amacimiz  y_pred'in, y_real'e yaklasmasi)\n",
    "        print(step, sess.run(weights), sess.run(biases)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30501825  0.3767944   0.39487764]\n",
      " [ 0.32714045  0.36743701  0.32770464]\n",
      " [ 0.38853812  0.38401783  0.38375115]]\n",
      "\n",
      "[[ 0.30501819  0.37679443  0.39487767]\n",
      " [ 0.32714039  0.36743698  0.32770458]\n",
      " [ 0.38853815  0.38401783  0.38375115]]\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(y_pred) # Modelden verileri almak için run metodunu bir değişkene atıyoruz\n",
    "print(prediction, end=\"\\n\\n\")\n",
    "print(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
